---
title: Lauren Liss at UX Camp Fall Home Edition 2020 (Video)
date: 2020-11-07 04:00 CDT
category: posts
tags: 2020, ux-camp
---

### Consent &amp; Ethics in Experience Design

<figure class="update-video">
  <iframe src="https://player.vimeo.com/video/474875174" allowfullscreen></iframe>
</figure>

Lauren Liss presented &#8220;Consent &amp; Ethics in Experience Design&#8221; at UX Camp Fall 2020. Enjoy! READMORE

As we rapidly approach &#8220;The Uncanny Valley&#8221; of experience design, what obligation do technology creators have in maintaining an environment of informed consent and ethics with their audience? This session will explore the realities and impact that persuasive design techniques (both intentional and not) play into how participants engage with technology.

We will look at examples of efficient, devious, deceptive design, as well as well-intentioned design choices that may have unintended consequences. We will discuss the idea of consent as it relates to the people that interact with our interface, and how we can morally augment their experiences for the greater good without leaving them in the dark.

### Lauren Liss

#### Assistant Professor, Interactive Arts + Media, Columbia College Chicago

Lauren Liss coordinates the Interaction Design major and the User Experience and Web Development minors in the Interactive Arts and Media (IAM) Department at Columbia College Chicago and has been a faculty member in this program since 2006. She teaches interface design, interaction theory, user experience and usability, and collaborative development.

Lauren also runs an interaction design company, Goodspark, which focuses on content management systems and usability analysis for small businesses, with a specialization in women-owned businesses and creative firms. She received her Masters in Education, Learning Design and Leadership, New Learning, from the University of Illinois, where she studied knowledge acquisition and educational theory through the lens of usability and technology.

​​​*The following transcript very likely contains typographical errors. Please forgive any mistakes!*

Hi Everyone. My name is Lauren, I&#8217;m an Assistant Professor at Columbia College here in Chicago. I coordinate the interaction design, Bachelor of Arts and Master of Arts programs, as well as our user experience and web development miners. I&#8217;ve been teaching there since 2006, and while I do teach practical production stuff in terms of user experience in human or design and collaborative development, I also focus a lot on the obligation that we have in those roles that it&#8217;s not just about making things&hellip; It&#8217;s about thinking about, we make those things, what impact they have, and what problems they&#8217;re solving. So the idea for this talk actually came from two different things that overlapped at the same time I was reading the book broadband, which is by Clare Evans, which I highly recommend, it&#8217;s about the role that women played in early computing. And then I also listened to a podcast episode at same time of IR that was called What if women built the Internet, and I re-consent, and that&#8217;s kind of where the overlap was and these two things. And so it really got into this idea of consent being really problematic with the way that we interact with the digital world, and this shouldn&#8217;t be surprised because consent broadly in our society is something that we&#8217;re not really great at handling.

And so some of that is kind of just this systemic issue and the way that things are built, both from a deceptive and manipulate standpoint, but also there are well-intentioned things that are not entirely consensual experiences, you can have all the best intentions in the world and you can still over-set the bounds of what&#8217;s ethical and what&#8217;s consensual, so when I set out to write this slide deck, I have a good friend of mine, that&#8217;s a fantastic editor, and I always said Her my stuff before I present and ask her to go through it&hellip; And she&#8217;s super detailed oriented, and she looked through it, she said, Okay, so the first number slide here, this originally said self as currency, and she goes, all of your other numbered slides, their complete Sundance, and that&#8217;s the only one that is not a complete sentence, so for continuity, it should say self as currency, and I was like, Oh, okay, and then I was like, Oh, that sentence feels gross. I hate&hellip; Well, I don&#8217;t like the idea of thinking about myself as currency, but that really is the proper way of saying it, the internet was created on this model that there isn&#8217;t a monetary border for the goods and services, so if we think about&hellip;

Especially predominantly in the 20th century, our society was built on bartering using monetary funds, meaning that I go by groceries, I stances for it, I go to the doctor, I exchange cash for it, I go to movies, I change cash for it, that&#8217;s the transaction that is happening, and with a lot of the services online, we don&#8217;t have that sort of transaction, we do with some, but if you look at the big consumers of our time and attention, if you&#8217;re looking at Facebook, Twitter, Instagram, there&#8217;s no direct transaction from a monetary standpoint, instead, the data about ourselves as human beings, that is the currency that pushes that economy forward and&hellip; So what do I mean when I say that? So it&#8217;s who I am and what I do. That&#8217;s the currency, or, What&#8217;s my name, what&#8217;s my number? All of this information about myself is the currency, and it&#8217;s a lot of information&hellip; And what&#8217;s tricky about this is that currency has power, and I&#8217;m using currency in this broader term of not just monetary currency, it has power, and when we own our currency, we have the power to withhold that currency, not necessarily from an efficacy standpoint, but we can use it to voice our own opinion, and we do that, right? This is something that we tend to do.

And when we don&#8217;t know the value of that currency and we&#8217;re not actually owning that currency, we can&#8217;t operate in that same way, and so what&#8217;s dangerous here is that there&#8217;s a lack of transparency about the value of our personal information. We actually have no idea what goes on with our personal information, there&#8217;s very little that needs to be legally disclosed, they need to disclose that they&#8217;re collecting it, but they don&#8217;t necessarily have to disclose how they&#8217;re using it, and so I imagine if that was a financial transaction, with monetary forms, we know how much money is worth, and so this comes to the real quandary, the value of currency is defined when it is spent, right. Monetary currency is fluctuate. The value transaction happens when you actually spend the currency, but we don&#8217;t know when that is happening, we don&#8217;t know how companies are spending it, and also they can keep reusing it over and over again. So it&#8217;s like giving someone a 5 bill and they turn around and use that 5 build, but they also get to keep that 5 Bill and I get to go to someone else with the 5 Babel, but they&#8217;re always keeping it.

And that&#8217;s tricky. That&#8217;s really complicated. So we lose Agency because we don&#8217;t know how when or how often that personal information is being used and we don&#8217;t understand its value, so us as human beings are a currency involved in a transaction that we&#8217;re not actually really a party to, that we don&#8217;t even know the value of it, or how it&#8217;s happening. So one of my favorite examples of this is, if you look at this picture and you know nothing about money, you would look at this and say, Okay, which one is better&hellip; So I have two kids, they&#8217;re 70 and 10. My daughter is older, my son is younger, and when they were littler, my son was about three. My daughter was six, they had found coins that were cleaning out the couch, and they had one coins, and I had told them that I see vacuum, they could keep whatever cords they found, so&hellip; Why at my son found a nickel, Arlo, my daughter dying&hellip; My older daughter knows that Adam is worth 10 cents, she understands some of the basics about currency, my son understands that money is a thing, and that&#8217;s about it, he doesn&#8217;t know the difference between a diamond, a nickel, and so our low terms to him and she goes, by it, I&#8217;ll trade you my dime for nickel, and why it looks at it and goes, Oh, well, the nice bigger&hellip;

That must mean that it&#8217;s more&hellip; Okay, yeah, let&#8217;s do that. So was that a consensual transaction&hellip; Yes, he technically agreed to it. Was it informed consent? Not at all. And was it ethical? Absolutely not. In the end, I intervened and made my daughter give my son both of the time and the nickel and she got neither of them&hellip; We don&#8217;t get to do that with these companies that use our information, so you might say like, Well, this is a two-way road. Right. We have to understand these things. We have to understand the value of these things. It&#8217;s not like we&#8217;re totally in the dark with this, we have some sort of obligation to this&hellip; For sure, yes, we have to take accountability for our actions, but it&#8217;s not really that simple. Let&#8217;s be real about this. If we were to read all of the privacy policies that we agree to in one year, it would take 76 days, we all know that we get presented with one of those policies and we do how class until the button changes color and I can click it. Okay, good. Done, it&#8217;s a race. If you actually read out loud the Amazon terms and conditions, it would take you nine hours, so&hellip;

We&#8217;re not doing that. No one has time to do that. And that&#8217;s not an accident. Right, we have consent fatigue, and it&#8217;s been designed that way, these things have been framed so that we will just participate in the process, and this is all wrapped up in a term called techno-social engineering, so when you set things up in a specific environment in a specific way people act like stimulus response machines. It&#8217;s very straightforward, we understand the circumstance, we understand that we kind of have no agency, we have no choice in it, and so we&#8217;re rational, we&#8217;re technically consenting, but it&#8217;s predictable and it&#8217;s not informed consent, and this is what&#8217;s tricky, there&#8217;s a difference between consent and informed consent and so you might say That feels gross to know that things are being programmed to elicit a specific outcome, and it&#8217;s like, That doesn&#8217;t feel good, &#8217;cause we&#8217;re not machines where people were actual human beings, but we do get treated like machines in the way that some things are designed&hellip; This is why I really try to get my students to use the word audience or participant instead of using users because just the language is important.

Language can have a big impact when we use the term user, that&#8217;s kind of faceless, it&#8217;s not personally using more personal language really helps. Alright, you might just say, okay, but people can just opt out, that&#8217;s a thing. If you don&#8217;t wanna participate in it. Just don&#8217;t participate in it. But it&#8217;s not that simple, even if you choose to fully act out of the whole thing and say, I&#8217;m gonna live off a grid, I&#8217;m not gonna be involved in any of this stuff, that information still finds a way to get into other people&#8217;s hands, either through overreach or even from other people. So that data doesn&#8217;t just come from us, and the transactions that we agree to and participate in, your personal information is also collected from other people without your consent. So a great example of this is Facebook. So Facebook laws data, they want who ask all of the data, and one of the ways that they do that is to create these design patterns where people don&#8217;t entirely recognize what it is that they&#8217;re participating in, and they&#8217;re praying on people&#8217;s efficiency or what they think is something that&#8217;s actually helpful to them, and sometimes these things are designed in a way to not be helpful to the participant at all, but for sure be helpful to the company of what their goal is is to get as much information&hellip;

So Facebook has what are called shadow profiles, which you may have heard of, it&#8217;s this collection of information about users that is not publicly facing, but that is stored within the Facebook environment. And so let&#8217;s say, for example, my mom joins Facebook, she&#8217;s going through the process of onboarding it, and she gets presented with the screen that says, Hey, do you wanna&hellip; Do you want us to get your contact so we can connect you with those people on Facebook and you can become friends, and she&#8217;s like, Oh yeah, it feels bad being a new&hellip; I wanna hurry up to connect with as many people as possible so that I have lots of friends on Facebook, because it doesn&#8217;t feel good to be a beginner. And so she says, Yes, that is super helpful. Thank you, Facebook. I will opt into that, and she&#8217;s thinking that it&#8217;s just gonna make some connections with the people she has on her phone and the people that are already on Facebook and automate that process for her, but what it&#8217;s also doing is grabbing all of the contact information from her phone, whether or not those people are on Facebook and storing it, so it could be that my mom and her address book has my cellphone number as well as my work phone number.

When I set up my Facebook account, I did not include my work number, I explicitly did not put that in there, I didn&#8217;t want that included within the Facebook environment, work as over here, Facebook is over here. And never the two shall meet. But now Facebook can do the deduction and say, Oh, this contact in the phone has this cell phone number, that&#8217;s the same as Lauren cellphone number, therefore, all this other information is also related to Lauren, like her birthday and her work phone number, and her address, all that information, and it zips it over into a shadow profile, and now Facebook has my work information in my home address, even though I didn&#8217;t give it to them, and so we haven&#8217;t provided that, and not only that, they&#8217;re stewarding that information about non-users, so people that have said, I&#8217;m not even gonna be on Facebook. They&#8217;re still gonna have trade profiles about those people with any information they&#8217;ve been able to pull from contacts of theirs that have shared it. So what&#8217;s great is that Facebook marketer under&hellip; I said, I now wanna think about koro files. That&#8217;s one of things that we do.

There was a bug in 2013 where if you downloaded all your user data from Facebook, you could see all of your sharpie information, and Facebook said, Oh&hellip; How was a bug? We fixed it. They fix the bug in the sense that now when you download your data, the shadow profile information isn&#8217;t included there, but they for sure still have it. So there&#8217;s a whole bunch of examples of houses happened, a man donated sperm to a couple only to have the child that they had show up as someone he should friend on Facebook later on in life, or a woman whose father&#8217;s mistress was recommended to her as a friend, 40 years later, right? No, that&#8217;s not a great feeling. None of those things feel good, and you may say, Well, but sometimes that stuff is helpful, some of those features are genuinely helpful to people, for sure can be the collecting of information about us can help automate and augment things about our lives. Right, it does make lives easier, but we&#8217;re imperfect by design, the way that our brains are set up, we compartmentalize, memories, degrade, we keep things separated, we don&#8217;t always need to know or want to know all of the information or patterns or things that can be divided by our actions, I don&#8217;t know how many of you are the person where your friends call you up when something weird was on the technology and they&#8217;re like, Yeah, what&#8217;s this thing&hellip;

Help me figure it out. I&#8217;m that person for all of my friends, and one of my favorites was a girlfriend who called me and she was like, Okay, girl, I need you to walk me through this thing that just happened because I wanna know how to make it never happen again. And you gotta tell me&hellip; And I was like, Oh yeah, let&#8217;s talk about it. And she goes, Okay, so I&#8217;ve been seeing this guy for a while. Were death&#8217;s not my boyfriend? We&#8217;re definitely not in a relationship, and I was just getting in the car, right? To go to the grocery store. And I looked at my phone to start Spotify, and it gave me a little notification on my lock screen, and it said 13 minutes to one to three ABC street, which was not her boy friends address, but totally her boyfriend&#8217;s addressed. And she was so freaked out by it that he threw her phone across the car, and she said, I don&#8217;t want my phone&hellip; Knowing that I&#8217;m in a relationship, before I&#8217;m ready to understand that I&#8217;m in a relationship. She didn&#8217;t want that pattern knowledge, even though she definitely went to his house every Tuesday night or on the same time, she didn&#8217;t want her phone to be telling her that, and that&#8217;s because you&#8217;re opted into that feature by default and to actually opt out of it takes seven screens, you have to go through in the iOS settings to do that.

These sorts of things shouldn&#8217;t be a thing, here is an ad that a girlfriend sent me that she had on Facebook, and this was the screen that it showed her after she hit the ad, and I looked at these little pill tabs here, and I would have loved to bend the meeting where they figured out what are we gonna write on these pill tabs knows too much. That sounds like a good one. Let&#8217;s go with that copy vision be a thing, we shouldn&#8217;t be using information on people to present them with things that maybe make them feel uncomfortable, and then gives them this option here that they have to fill out, that&#8217;s just not something we should be participating in. So it&#8217;s not just about the consent and the experience, it&#8217;s also about the ethical ramifications of those choices, so we have an obligation as people that create these items to be responsible for the transaction that&#8217;s happening, and so we&#8217;re gonna look at two quotes here, so the first one is from herdsmen who kind of foresaw the attention economy back in 1971, the more information there is, there&#8217;s a poverty of attention, which we are in that now we are in an attention economy where we have to be thoughtful and we&#8217;re constantly over-burden with information, and then pull Berio has another one that says, when you invent the plane, you also invent the plane crash, every technology carries its own negativity, which is invented at the same time, so the idea here is that the things that we create and we put out into the world, are also going to create negative impacts, and we need to be aware of those, not just after they&#8217;ve been launched, but try to do some contingency planning to notice those things ahead of time and mitigate them as much as possible, because the struggle is real in this&hellip;

The way that the attention economy and pulling in our personal information and keeping us engaged in keeping us giving them more and more currency is having serious mental manston of negativity on the way that we live it. So you look at all of these terms, these are all related to our anxieties with this way that we interact with the digital world around us, have one is email apnea, the June 80% of people stop breathing or have shallow breathing when they&#8217;re reading email. How sanitary ing to think about&hellip; And if we&#8217;re pinging people to check their email all the time, we&#8217;re putting them in the cycle where that&#8217;s happening all the time. Alright, so you might look at that and be like, Alright, I get it. And bought in. All those things are bad. What exactly am I supposed to do about it? So there&#8217;s eight things we&#8217;re gonna go through, I actually used them when I was writing unit was a very meta process because I really wanted to have 10 things &#8217;cause it sounds nicer, 10 tips, but I tried to use economy of words and I was like, No, it&#8217;s actually, just a tip.

Or stick with the eight. So the first one is to be transparent, right, this build trust with your users, it&#8217;s not about not needing to take any information from them at all, just be thoughtful about it and be clear about why you need that information, the more trust you can build with people the better off the experiences for them, the more involved in are the greater sense of agency they have in the process. The next one is to speak in plain language, like talk&hellip; Like you talk to people. One of my favorite activities that I have students do in class is any time they&#8217;ve written any copy that goes on an interface, I have them role play it with each other and say it out loud, because frequently the things that we write down on a piece of paper or not things you would say out of our mouths. And so I say, Imagine that your interface that you&#8217;re designing is a person, how do you want that conversation to go, what kinds of conversations do you&hellip; To have with other people, we also do Aron Walters design personas, product personas, which allows you to create user personas for the product itself, not just for the audience, which helps a ton in that&hellip;

Use economy of words, right? Ditch legally is where you can&hellip; Or if you have to have it, just do a little TLD at the top, do a little bullet point list of like, Hey, we are legally required to say all this stuff, but here&#8217;s the high level points, if you just wanna see that because people will read that and the ability of that, because it shows that you value their time and then collect just what&#8217;s necessary, we have a tendency to think that when we are engaging with users and getting personal information from them, that it&#8217;s like supermarket sweep up in here, just everything of the shells to card. Why do we need all of the information? And I get it, if part of the underlying value of whatever the product is that we&#8217;re building is taking that personal information and behaviors and things you&#8217;ll do and using that as currency that we then sell off&hellip; Yeah, having more information is better. But way that, right? Do you actually need all of it, if you don&#8217;t need all of it, don&#8217;t take all of it, just take what you need. Or if you do need a lot of information to start with the minimum, build trust with users and then ask for additional information later on, don&#8217;t demand it, just ask it.

There&#8217;s a difference there. Think about the way that you engage with people, with the products that you create, do you need vegetation? Do you need to push notifications all the time? When we get distracted, it takes on average 23 minutes to get back on topic, and we get interrupted by things all the time, we get interrupted from notifications on our phone or the things are on our computer, and it pulls us out of our line of thought and that&#8217;s a huge waste of productivity, so think about the ways that you engage with people or give them those sorts of notifications, value attention and information, don&#8217;t just treat the participants or customers of your product or service like their currency, treat them whole people. Let them know that you care about their information, that you&#8217;re going to keep it safe. The next one is to consider alternatives, constraint is good for design. I do this activity with students called, let&#8217;s pretend we can&hellip; Where when they are pitching ideas to me, I go through and look for a specific kind of functions like using location services or poaching notifications, and I say, Okay, let&#8217;s pretend that they just don&#8217;t&hellip;

They&#8217;re not gonna use location services, what might be a way that you can solve this problem without requiring tracking from the user, is there a way to do that because constraint is good for the creative process. And then finally, align goals, figure out what the business goals are, for sure, it has to be financially solvent. Some of those things you have to do, but I can&#8217;t bill things to be true. Can you hold the users needs in one hand and the business goals in one hand, and find the places that they overlap or address where it might cause harm to the audience. So you might say, Do I have to do with us? I hope you wanna do it, but you kind of have to&hellip; With new legislation, some of these things are required, and so in reality, we shouldn&#8217;t just settle at the bar of what is legally required, we should be just creating higher than that, we should care about our users and value them, and not just do the bare minimum of what is legally mandated? Because true human-centered design holds at its core the humans themselves, we make things for broad audiences of people, and that&#8217;s really tremendous responsibility and an awesome power, and so we should aim higher than that.

So you can start small. The small changes on their own, they won&#8217;t be enough, but it&#8217;s still worthwhile. It&#8217;s about a mindset shift. And you can make things better. The Center for Humane Technology is another great resource. I have no direct involvement, it&#8217;s just a good resource to have on hand and that is it? Any questions on
